\documentclass[times,twocolumn,final,authoryear]{elsarticle}

\usepackage{prletters}
\usepackage{framed,multirow}
%\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
%\usepackage[table]{xcolor}
%\usepackage{tabularx}
%\usepackage[backend=bibtex,style=model2-names]{biblatex}
\usepackage{subcaption}
\usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes}
\usepackage{multirow}
\usepackage{makecell}
% \newcommandx{\unsure}[2][1=]{\todo[linecolor=red,backgroundcolor=red!25,bordercolor=red,#1]{#2}}
% \newcommandx{\change}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=blue,#1]{#2}}
% \newcommandx{\info}[2][1=]{\todo[linecolor=OliveGreen,backgroundcolor=OliveGreen!25,bordercolor=OliveGreen,#1]{#2}}
% \newcommandx{\improvement}[2][1=]{\todo[linecolor=Plum,backgroundcolor=Plum!25,bordercolor=Plum,#1]{#2}}
% \newcommandx{\thiswillnotshow}[2][1=]{\todo[disable,#1]{#2}}

% Formatting
% \setlength{\parindent}{4em}
%\setlength{\parskip}{1em}

%\newcommand{\X}{\cellcolor{blue!25}} 
%\newcolumntype{K}[1]{>{\centering\arraybackslash}p{#1}}
%\newcolumntype{C}{>{\centering\arraybackslash}X}

\linespread{0.98}
\hyphenation{ra-ting}

\captionsetup[figure]{labelfont=bf,textfont=bf,labelsep=period}
\captionsetup[table]{labelfont=bf,textfont=bf,justification=centering,labelsep=period,aboveskip=2pt}

\interfootnotelinepenalty=10000

\journal{Pattern Recognition Letters}

\begin{document}

\clearpage
\thispagestyle{empty}
\ifpreprint
  \vspace*{-1pc}
\fi

\begin{table*}[!th]
\ifpreprint\else\vspace*{-5pc}\fi

\section*{Graphical Abstract (Optional)}
To create your abstract, please type over the instructions in the
template box below.  Fonts or abstract dimensions should not be changed
or altered. 

\vskip1pc
\fbox{
\begin{tabular}{p{.4\textwidth}p{.5\textwidth}}
\bf Continuous real-time annotation fusion correction via rank-based spatial warping  \\
Brandon M. Booth, Karel Mundnich, Shrikanth S. Narayanan \\[1pc]
\includegraphics[width=.3\textwidth]{top-elslogo-fm1.pdf}
& 
Human annotations are noisy and prone to influence from several factors including personal bias, task ambiguity, environmental distractions, health state, and more.  These annotations, however, are of integral value in human behavior studies, and in design and evaluation of machine learning applications, especially those involving hidden mental states that cannot effectively be measured or assessed by other means.  We propose a novel method for extending continuous real-time annotation fusion approaches to generate accurate ground truth estimates.  We validate our approach in a mechanically simple but perceptually demanding psychophysical annotation experiment where an objective truth is known.  Our method yields a ground truth in better agreement with the objective truth than state-of-the-art approaches and can be used to provide a more accurate fused annotation for real data.
%}\\
\end{tabular}
}

\end{table*}

\end{document}